{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Walkthrough: Predicting the World Cup #\n",
    "\n",
    "*Sorin Peste (sorinpeste@gmail.com)*\n",
    "\n",
    "## Intro ##\n",
    "\n",
    "This is a walkthrough on using Machine Learning while trying to predict who is going to win the next [FIFA World Cup](http://www.fifa.com/worldcup/index.html).\n",
    "\n",
    "We're going to use historical information about international football (soccer) matches to build a model, which is going to give us the ability to predict future match results.\n",
    "\n",
    "Afterwards, we're going to use that model to run multiple simulations of the next World Cup tournament, and produce statistics about which teams are the most likely to win it all.\n",
    "\n",
    "This document is meant for people who are new to Machine Learning, and want to better understand the data science process, as well as the R language.\n",
    "\n",
    "> NOTE: If you attended any of my presentations about this walkthrough, you can find the [presentation slides here](http://slides.com/sorinpeste/fun-with-machine-learning/).\n",
    "\n",
    "> NOTE 2: The GitHub containing all the code I used is [here](https://github.com/neaorin/PredictTheWorldCup). You can also find the Javascript code I used to acquire the [historical matches data](https://github.com/neaorin/PredictTheWorldCup/tree/master/acquisition/fifa) from the FIFA website, as well as the [Python program](https://github.com/neaorin/PredictTheWorldCup/blob/master/src/TournamentSim/simulateworldcup.py) which simulates the tournament thousands of times.  \n",
    "\n",
    "## Customizing the Tutorial\n",
    "\n",
    "If you want to do this walkthrough on your own machine, or if you'd like to customize it, you can clone this notebook by using the **Clone** button at the top of this page. This will copy the entire notebook into your own Azure Notebooks workspace, where you can edit it.\n",
    "\n",
    "You can also find an [R source file containing the entire code](https://github.com/neaorin/PredictTheWorldCup/blob/master/src/WorldCup.R) on my GitHub repo. Open that with the editor of your choice - [RStudio](https://www.rstudio.com/) is a popular one.\n",
    "\n",
    "With that out of the way, let's begin!\n",
    "\n",
    "## The Process ##\n",
    "\n",
    "Below is a typical workflow for a Data Science project such as ours.\n",
    "\n",
    "![Data Science Project Workflow](https://raw.githubusercontent.com/neaorin/PredictTheWorldCup/master/images/datascience_process.jpg)\n",
    "\n",
    "## Our Objective ##\n",
    "\n",
    "The first step is defining an objective, an outcome for our model to predict:\n",
    "\n",
    "> Given a match between two teams, what is the **expected goal differential** at the end of the match?\n",
    "\n",
    "In other words, we're going to attempt to predict the `outcome` variable in the table below, which is the difference between the number of goals scored by `team1` and the number of goals scored by `team2`.\n",
    "\n",
    "![Outcome - goal differential](https://raw.githubusercontent.com/neaorin/PredictTheWorldCup/master/images/goaldiff.png)\n",
    "\n",
    "Let's note that the `outcome` value can be zero (for draws), positive (whenever `team1` wins) but also negative (whenever `team2` wins the match).\n",
    "\n",
    "## The Data ##\n",
    "\n",
    "### Matches ###\n",
    "\n",
    "We're going to use a dataset containing more than 33 thousand international football matches played between 1950 and 2017. All these matches are played between senior men's national teams - there are no club matches, and no youth / women's games.\n",
    "\n",
    "The dataset is available as [CSV](https://raw.githubusercontent.com/neaorin/PredictTheWorldCup/master/input/matches.csv) and [JSON](https://raw.githubusercontent.com/neaorin/PredictTheWorldCup/master/input/matches.json) files.\n",
    "\n",
    "Below is a small sample from the JSON file:\n",
    "\n",
    "```json\n",
    "[\n",
    "    {\n",
    "        \"date\": \"19560930\",\n",
    "        \"team1\": \"AUT\",\n",
    "        \"team1Text\": \"Austria\",\n",
    "        \"team2\": \"LUX\",\n",
    "        \"team2Text\": \"Luxembourg\",\n",
    "        \"resText\": \"7-0\",\n",
    "        \"statText\": \"\",\n",
    "        \"venue\": \"Ernst Happel Stadium - Vienna , Austria\",\n",
    "        \"IdCupSeason\": \"10\",\n",
    "        \"CupName\": \"FIFA World Cup™ Qualifier\",\n",
    "        \"team1Score\": \"7\",\n",
    "        \"team2Score\": \"0\"\n",
    "    },\n",
    "    {\n",
    "        \"date\": \"19561003\",\n",
    "        \"team1\": \"IRL\",\n",
    "        \"team1Text\": \"Republic of Ireland\",\n",
    "        \"team2\": \"DEN\",\n",
    "        \"team2Text\": \"Denmark\",\n",
    "        \"resText\": \"2-1\",\n",
    "        \"statText\": \"\",\n",
    "        \"venue\": \"DUBLIN - Dublin , Republic of Ireland\",\n",
    "        \"IdCupSeason\": \"10\",\n",
    "        \"CupName\": \"FIFA World Cup™ Qualifier\",\n",
    "        \"team1Score\": \"2\",\n",
    "        \"team2Score\": \"1\"\n",
    "    },\n",
    "    ...\n",
    "]\n",
    "```\n",
    "\n",
    "### Teams ###\n",
    "\n",
    "We also have some information regarding the international associations and the FIFA confederations they are part of. We may find that useful when looking at past opponents of a team.\n",
    "\n",
    "This dataset is available as a [CSV](https://raw.githubusercontent.com/neaorin/PredictTheWorldCup/master/input/teams.csv) file.\n",
    "\n",
    "Below is a sample of the data:\n",
    "\n",
    "```csv\n",
    "confederation,name,fifa_code,ioc_code\n",
    "\n",
    "CAF,Algeria,ALG,ALG\n",
    "CAF,Angola,ANG,ANG\n",
    "CAF,Benin,BEN,BEN\n",
    "CAF,Botswana,BOT,BOT\n",
    "...\n",
    "AFC,Afghanistan,AFG,AFG\n",
    "AFC,Australia,AUS,---\n",
    "AFC,Bahrain,BHR,BRN\n",
    "AFC,Bangladesh,BAN,BAN\n",
    "...\n",
    "UEFA,Albania,ALB,ALB\n",
    "UEFA,Andorra,AND,AND\n",
    "UEFA,Armenia,ARM,ARM\n",
    "UEFA,Austria,AUT,AUT\n",
    "...\n",
    "CONMEBOL,Argentina,ARG,ARG\n",
    "CONMEBOL,Bolivia,BOL,BOL\n",
    "CONMEBOL,Brazil,BRA,BRA\n",
    "CONMEBOL,Chile,CHI,CHI\n",
    "```\n",
    "\n",
    "### Qualified for the World Cup ###\n",
    "\n",
    "Last, we have a list of the teams which have qualified for the World Cup, and their group stage draw.\n",
    "\n",
    "> NOTE: As of October 2017, the group stage draw for the 2018 World Cup has yet to take place; what we have is a random draw scenario.\n",
    "\n",
    "This dataset is available as a [CSV](https://raw.githubusercontent.com/neaorin/PredictTheWorldCup/master/src/TournamentSim/wc2018qualified.csv) file.\n",
    "\n",
    "Below is a sample of the data:\n",
    "\n",
    "```csv\n",
    "name,draw\n",
    "\n",
    "RUS,A1\n",
    "IRN,F2\n",
    "KOR,A3\n",
    "JPN,G2\n",
    "KSA,H2\n",
    "AUS,B3\n",
    "TUN,A2\n",
    "NGA,B2\n",
    "CIV,C2\n",
    "...\n",
    "```\n",
    "\n",
    "\n",
    "## Setup ##\n",
    "\n",
    "First, we're going to load a few R libraries from [CRAN](https://cran.r-project.org/) - the Comprehensive R Archive Network - into our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T13:42:57.410808Z",
     "start_time": "2018-06-18T13:42:55.125Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in install.packages(\"readr\"):\n",
      "“installation of package ‘readr’ had non-zero exit status”Updating HTML index of packages in '.Library'\n",
      "Making 'packages.html' ... done\n"
     ]
    }
   ],
   "source": [
    "install.packages('readr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T14:28:05.812634Z",
     "start_time": "2018-06-18T14:28:05.828Z"
    }
   },
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in parse(text = x, srcfile = src): <text>:1:1: unexpected input\n1: %ls\n    ^\n",
     "output_type": "error",
     "traceback": [
      "Error in parse(text = x, srcfile = src): <text>:1:1: unexpected input\n1: %ls\n    ^\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T14:27:50.508261Z",
     "start_time": "2018-06-18T14:27:50.522Z"
    }
   },
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in parse(text = x, srcfile = src): <text>:1:1: unexpected input\n1: %which R\n    ^\n",
     "output_type": "error",
     "traceback": [
      "Error in parse(text = x, srcfile = src): <text>:1:1: unexpected input\n1: %which R\n    ^\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "which R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T13:42:29.160515Z",
     "start_time": "2018-06-18T13:42:29.115Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "“S3 methods ‘as.col_spec.NULL’, ‘as.col_spec.character’, ‘as.col_spec.col_spec’, ‘as.col_spec.default’, ‘as.col_spec.list’, ‘format.col_spec’, ‘output_column.POSIXt’, ‘output_column.default’, ‘output_column.double’, ‘print.col_spec’, ‘print.collector’, ‘print.date_names’, ‘print.locale’ were declared in NAMESPACE but not found”"
     ]
    },
    {
     "ename": "ERROR",
     "evalue": "Error: package or namespace load failed for ‘readr’ in library.dynam(lib, package, package.lib):\n shared object ‘readr.so’ not found\n",
     "output_type": "error",
     "traceback": [
      "Error: package or namespace load failed for ‘readr’ in library.dynam(lib, package, package.lib):\n shared object ‘readr.so’ not found\nTraceback:\n",
      "1. library(readr)",
      "2. tryCatch({\n .     attr(package, \"LibPath\") <- which.lib.loc\n .     ns <- loadNamespace(package, lib.loc)\n .     env <- attachNamespace(ns, pos = pos, deps)\n . }, error = function(e) {\n .     P <- if (!is.null(cc <- conditionCall(e))) \n .         paste(\" in\", deparse(cc)[1L])\n .     else \"\"\n .     msg <- gettextf(\"package or namespace load failed for %s%s:\\n %s\", \n .         sQuote(package), P, conditionMessage(e))\n .     if (logical.return) \n .         message(paste(\"Error:\", msg), domain = NA)\n .     else stop(msg, call. = FALSE, domain = NA)\n . })",
      "3. tryCatchList(expr, classes, parentenv, handlers)",
      "4. tryCatchOne(expr, names, parentenv, handlers[[1L]])",
      "5. value[[3L]](cond)",
      "6. stop(msg, call. = FALSE, domain = NA)"
     ]
    }
   ],
   "source": [
    "library(readr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T13:41:55.656027Z",
     "start_time": "2018-06-18T13:41:51.224Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: pacman\n",
      "Warning message in utils::install.packages(package, ...):\n",
      "“installation of package ‘readr’ had non-zero exit status”Updating HTML index of packages in '.Library'\n",
      "Making 'packages.html' ... done\n",
      "\n",
      "readr installed\n",
      "Warning message:\n",
      "“S3 methods ‘as.col_spec.NULL’, ‘as.col_spec.character’, ‘as.col_spec.col_spec’, ‘as.col_spec.default’, ‘as.col_spec.list’, ‘format.col_spec’, ‘output_column.POSIXt’, ‘output_column.default’, ‘output_column.double’, ‘print.col_spec’, ‘print.collector’, ‘print.date_names’, ‘print.locale’ were declared in NAMESPACE but not found”Warning message in pacman::p_load(dplyr, zoo, data.table, ggplot2, scales, readr, :\n",
      "“Failed to install/load:\n",
      "readr”"
     ]
    }
   ],
   "source": [
    "# prepare the R environment\n",
    "if (!require(\"pacman\")) install.packages(\"pacman\")\n",
    "pacman::p_load(\n",
    "  dplyr,            # Data munging functions\n",
    "  zoo,              # Feature engineering rolling aggregates\n",
    "  data.table,       # Feature engineering\n",
    "  ggplot2,          # Graphics\n",
    "  scales,           # Time formatted axis\n",
    "  readr,            # Reading input files\n",
    "  stringr,          # String functions\n",
    "  Amelia,           # missing data evaluation\n",
    "  randomForest,     # Random forests\n",
    "  corrplot,         # correlation plots\n",
    "  Metrics,          # Eval metrics for ML\n",
    "  vcd               # Visualizing discrete distributions\n",
    ")\n",
    "    \n",
    "# set options for plots\n",
    "options(repr.plot.width=6, repr.plot.height=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T13:42:02.469905Z",
     "start_time": "2018-06-18T13:42:02.415Z"
    }
   },
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in read_csv(\"matches.csv\"): could not find function \"read_csv\"\n",
     "output_type": "error",
     "traceback": [
      "Error in read_csv(\"matches.csv\"): could not find function \"read_csv\"\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "# Load the matches data\n",
    "\n",
    "if(!file.exists(\"matches.csv\")){\n",
    "    tryCatch(download.file('https://github.com/neaorin/PredictTheWorldCup/raw/master/input/matches.csv'\n",
    "                           ,destfile=\"./matches.csv\",method=\"auto\"))\n",
    "}\n",
    "                \n",
    "if(file.exists(\"matches.csv\")) matches_original <- read_csv(\"matches.csv\")\n",
    "    \n",
    "head(matches_original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's perform some basic cleanup on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T13:41:11.100057Z",
     "start_time": "2018-06-18T13:41:06.723Z"
    }
   },
   "outputs": [],
   "source": [
    "# eliminate any duplicates that may exist in the dataset\n",
    "matches <- matches_original %>%\n",
    "  distinct(.keep_all = TRUE, date, team1, team2)\n",
    "\n",
    "# the date field is formatted as a string (e.g. 19560930) - transform that into R date\n",
    "matches$date <- as.POSIXct(strptime(matches$date, \"%Y%m%d\"), origin=\"1960-01-01\", tz=\"UTC\")\n",
    "\n",
    "# generate an id column for future use (joins etc)\n",
    "matches$match_id = seq.int(nrow(matches))\n",
    "\n",
    "head(matches)\n",
    "summary(matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration and Visualisation ##\n",
    "\n",
    "More often than not, the best way to understand a dataset is to turn it into a picture. \n",
    "\n",
    "Or rather, multiple pictures.\n",
    "\n",
    "Fortunately, R has some useful tools in this regard - and a lot of them come with the very popular [ggplot2](http://ggplot2.org/) package. \n",
    "\n",
    "Some useful resources when learning to use ggplot2 are:\n",
    "- The [R for Data Science](http://r4ds.had.co.nz/) ebook, Chapter *3. Data Visualisation*\n",
    "- [Data Visualization with ggplot2 Cheat Sheet](https://www.rstudio.com/wp-content/uploads/2015/03/ggplot2-cheatsheet.pdf)\n",
    "- The [ggplot2 explorer app](http://databall.co/shiny/shinyggplot/)\n",
    "- [Essential Cheat Sheets](https://github.com/kailashahirwar/cheatsheets-ai) for deep learning and machine learning researchers\n",
    "\n",
    "For example, let's get a sense on the number of games which have been played over the years, and how close they were from a competitive standpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T13:41:11.104938Z",
     "start_time": "2018-06-18T13:41:06.993Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# how many international games have been played over the years?\n",
    "matches %>%\n",
    "  ggplot(mapping = aes(year(date))) +\n",
    "    geom_bar(aes(fill=CupName), width=1, color=\"black\") +\n",
    "    theme(legend.position = \"bottom\", legend.direction = \"vertical\") + ggtitle(\"Matches played by Year\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T13:41:11.107109Z",
     "start_time": "2018-06-18T13:41:07.000Z"
    }
   },
   "outputs": [],
   "source": [
    "# how many goals have been scored per game over the years? \n",
    "matches %>%\n",
    "  dplyr::group_by(year = year(date)) %>%\n",
    "  dplyr::summarize(\n",
    "    totalgames = n(),\n",
    "    totalgoals = sum(team1Score + team2Score),\n",
    "    goalspergame = totalgoals / totalgames\n",
    "    ) %>%\n",
    "  ggplot(mapping = aes(x = year, y = goalspergame)) +\n",
    "    geom_point() +\n",
    "    geom_smooth(method = \"loess\") + ggtitle(\"Goals scored per game, over time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T13:41:11.109069Z",
     "start_time": "2018-06-18T13:41:07.006Z"
    }
   },
   "outputs": [],
   "source": [
    "# what values is our dataset missing?\n",
    "Amelia::missmap(matches, main = \"Missing values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few things we can note from our graphs above, as well as from examining the dataset:\n",
    "\n",
    "Although our sample size of matches played before 1960 is fairly small, we can note that the era of free-wheeling, mostly attacking football coming to an end with the perfection of devensive tactics like [catenaccio](https://en.wikipedia.org/wiki/Catenaccio) in Italy, and eventually with the era of [Total Football](https://en.wikipedia.org/wiki/Total_Football) which took off in the early '70s. We may need to factor in some of these developments into our model. \n",
    "\n",
    "`pen1Score` and `pen2Score` are only present whenever a match ended on penalties. All missing values indicate a match which did not get to a penalty shootout. Therefore, the values aren't really missing, so we can use these features if we want; however, the number of observations is fairly small, and penalty shoot-outs do have a reputation of being a lottery of sorts, especially at the highest level of play when the prize is advancement to a later stage of the World Cup. \n",
    "\n",
    "One additional thing to note is that, for matches ending on penalties, `team1Score` = `team2Score`; these values do *not* include the penalty shoot-out goals; still, those games weren't really draws, since they were decided on penalties. From a purely performance standpoint however, we might decide to consider a team losing on penalties as being closer to a draw than an actual loss.\n",
    "\n",
    "`statText` is also only present for matches which *didn't* end in regulation time. It includes extra-time matches as well as penalty shoot-outs as above. Unlike `pen1Score` and `pen2Score` however, `team1Score` and `team2Score` do include all the goals scored in extra time as well. Same as before, we might decide that a team performed better if they lost in extra time vs. a loss in regulation; however, we will disregard this field for now. \n",
    "\n",
    "`venue` is interesting for the purpose of determining the home team, which in football has a distinct advantage (as we will later conclude). However, since `venue` is a text field, we will need to do some pattern matching with team names to determine the correct home team, which may present several problems. Also, about 15 percent of values are missing for this column, which will force us to consider these matches as being played in a neutral venue.\n",
    "\n",
    "`CupName` can be useful to determine whether a game was a played as a friendly, a qualifier, or a final tournament. Simple pattern matching will be enough for this task.\n",
    "\n",
    "`IdCupSeason` can be ignored at this time.\n",
    "\n",
    "`resText` can be ignored as all the information is also contained in other non-text fields.\n",
    "\n",
    "Finally, we may have an issue with the fact that `team1` consistently performs better than `team2` - likely because most of the games list the home team first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T13:41:11.110968Z",
     "start_time": "2018-06-18T13:41:07.281Z"
    }
   },
   "outputs": [],
   "source": [
    "summary(matches$team1Score - matches$team2Score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Mean` value for the goal differential is greater than 0.6, which may present a problem later on when training the model - it may capture this bias *`team1` is better than `team2`*, which is something we'd rather avoid, especially since the World Cup final tournament is played in a single country.\n",
    "\n",
    "So let's get rid of that by simply randomizing the order in which teams are listed for any one match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T13:41:11.112864Z",
     "start_time": "2018-06-18T13:41:07.756Z"
    }
   },
   "outputs": [],
   "source": [
    "set.seed(4342)\n",
    "matches$switch = runif(nrow(matches), min = 0, max = 1)\n",
    "\n",
    "matches <- bind_rows(\n",
    "  matches %>% dplyr::filter(switch < 0.5),\n",
    "  matches %>% dplyr::filter(switch >= 0.5) %>%\n",
    "    dplyr::mutate(\n",
    "      x_team2 = team2,\n",
    "      team2 = team1,\n",
    "      team1 = x_team2,\n",
    "      \n",
    "      x_team2Text = team2Text,\n",
    "      team2Text = team1Text,\n",
    "      team1Text = x_team2Text,\n",
    "\n",
    "      x_resText = \"\",\n",
    "      \n",
    "      x_team2Score = team2Score,\n",
    "      team2Score = team1Score,\n",
    "      team1Score = x_team2Score,\n",
    "      \n",
    "      x_team2PenScore = team2PenScore,\n",
    "      team2PenScore = team1PenScore,\n",
    "      team1PenScore = x_team2PenScore\n",
    "    ) %>%\n",
    "    dplyr::select(\n",
    "      date, team1, team1Text, team2, team2Text, resText, statText, venue, IdCupSeason, CupName, team1Score, team2Score, team1PenScore, team2PenScore, match_id, switch\n",
    "    )\n",
    "    ) %>% \n",
    "  dplyr::arrange(date) %>%\n",
    "  dplyr::select(-c(switch))\n",
    "\n",
    "summary(matches$team1Score - matches$team2Score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can create some aditional features about the matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T13:41:11.114746Z",
     "start_time": "2018-06-18T13:41:08.026Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# is the game played in a neutral venue\n",
    "matches$team1Home <- mapply(grepl, pattern=matches$team1Text, x=matches$venue, MoreArgs = list(fixed = TRUE, ignore.case = FALSE))\n",
    "matches$team2Home <- mapply(grepl, pattern=matches$team2Text, x=matches$venue, MoreArgs = list(fixed = TRUE, ignore.case = FALSE))\n",
    "matches$neutralVenue <- !(matches$team1Home | matches$team2Home)\n",
    "\n",
    "# text-matching the venue is not 100% accurate.\n",
    "# some games get TRUE for both team1 and team2 (ex. Congo DR vs Congo)\n",
    "# in this case, team1 is at home\n",
    "matches$team2Home[(matches$team1Home == TRUE) & (matches$team2Home == TRUE)] <- FALSE\n",
    "\n",
    "# game type: Friendly, Qualifier, Final Tournament\n",
    "matches$friendly <- FALSE\n",
    "matches$friendly[matches$CupName == \"Friendly\"] <- TRUE\n",
    "\n",
    "matches$qualifier <- FALSE\n",
    "matches$qualifier[matches$CupName %like% \"Qual\"] <- TRUE\n",
    "\n",
    "matches$finaltourn <- FALSE\n",
    "matches$finaltourn[matches$CupName %like% \"Final\"] <- TRUE\n",
    "matches$finaltourn[matches$CupName %like% \"Confederations Cup\"] <- TRUE\n",
    "\n",
    "head(matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we're going to eliminate friendly matches from the dataset.\n",
    "\n",
    "This decision is based on the observation that, with few exceptions, the main objective for a team playing a friendly is not to win it, but to evaluate its own players and tactics.\n",
    "\n",
    "For this reason it's not uncommon for friendlies to allow an unlimited number of substitutions, and for a team to roll out its entire squad during a friendly game.\n",
    "\n",
    "If you'd like to experiment with keeping friendlies in the dataset, you can comment out the line below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T13:41:11.116921Z",
     "start_time": "2018-06-18T13:41:08.366Z"
    }
   },
   "outputs": [],
   "source": [
    "# only use official matches (no friendlies)\n",
    "matches <- matches %>% dplyr::filter(friendly == FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Up until this point we've only looked at individual matches. However, what we really need is to look at each team's performance over its history. \n",
    "\n",
    "When we build our predictive model, we'd like to supply it with as many features about each of the teams about to be involved in a match. For that, we need to have a team-centric dataset with historical data.\n",
    "\n",
    "Building this dataset is simple: take each observation in `matches` - which has the form *\"team1 vs team2\"* - and produce two separate observations of the form *\"team1 played against team2\"* and *\"team2 played against team1\"* respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T13:41:11.118800Z",
     "start_time": "2018-06-18T13:41:08.672Z"
    }
   },
   "outputs": [],
   "source": [
    "# transform the matches table into a team performance table, where each team being \n",
    "# involved in a game is a separate observation (row)\n",
    "\n",
    "teamperf <- bind_rows(\n",
    "    (matches %>%\n",
    "    dplyr::mutate(\n",
    "      name = team1,\n",
    "      opponentName = team2,\n",
    "      homeVenue = team1Home,\n",
    "      neutralVenue = neutralVenue,\n",
    "      gs = team1Score,\n",
    "      ga = team2Score,\n",
    "      gd = gs - ga,\n",
    "      w = (team1Score > team2Score),\n",
    "      l = (team1Score < team2Score),\n",
    "      d = (team1Score == team2Score),\n",
    "      friendly = friendly,\n",
    "      qualifier = qualifier,\n",
    "      finaltourn = finaltourn\n",
    "    ) %>%\n",
    "    dplyr::select (match_id, date, name, opponentName, homeVenue, neutralVenue, gs, ga, gd, w, l, d, friendly, qualifier, finaltourn))\n",
    "    ,\n",
    "    (matches %>%\n",
    "    dplyr::mutate(\n",
    "      name = team2,\n",
    "      opponentName = team1,\n",
    "      homeVenue = team2Home,\n",
    "      neutralVenue = neutralVenue,\n",
    "      gs = team2Score,\n",
    "      ga = team1Score,\n",
    "      gd = gs - ga,\n",
    "      w = (team1Score < team2Score),\n",
    "      l = (team1Score > team2Score),\n",
    "      d = (team1Score == team2Score),\n",
    "      friendly = friendly,\n",
    "      qualifier = qualifier,\n",
    "      finaltourn = finaltourn\n",
    "    ) %>%\n",
    "      dplyr::select (match_id, date, name, opponentName, homeVenue, neutralVenue, gs, ga, gd, w, l, d, friendly, qualifier, finaltourn))\n",
    "  ) %>%\n",
    "  dplyr::arrange(date)\n",
    "\n",
    "head(teamperf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to capture some information about how good each team is, let's define a **winning percentage** formula:\n",
    "\n",
    "`winpercentage = (wins + 0.5 * draws) / games played`\n",
    "\n",
    "Then, let's plot that for each team which has played a significant number of games.\n",
    "\n",
    "We're going to define the win percentage formula and plot as R functions, since we might want to re-use them after we further tweak our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T13:41:11.120702Z",
     "start_time": "2018-06-18T13:41:08.999Z"
    }
   },
   "outputs": [],
   "source": [
    "# Out of the teams who have played at least 100 games, what are the winning percentages for each of those teams?\n",
    "\n",
    "formula_winpercentage <- function(totalgames, wins, draws) {\n",
    "    return ((wins + 0.5 * draws) / totalgames)\n",
    "}\n",
    "\n",
    "plot_winpercentage <- function(teamperf, mingames) {\n",
    "  teamperf %>%\n",
    "  group_by(name) %>%\n",
    "  summarize(\n",
    "    totalgames = n(),\n",
    "    wins = length(w[w==TRUE]),\n",
    "    draws = length(d[d==TRUE]),\n",
    "    winpercentage = formula_winpercentage(totalgames, wins, draws)\n",
    "  ) %>%\n",
    "  filter(totalgames >= mingames ) %>%\n",
    "  ggplot(mapping = aes(x = winpercentage, y = totalgames)) +\n",
    "  geom_point(size = 1.5) + \n",
    "  geom_text(aes(label=name), hjust=-.2 , vjust=-.2, size=3) +\n",
    "  geom_vline(xintercept = .5, linetype = 2, color = \"red\") +\n",
    "  ggtitle(\"Winning Percentage vs Games Played\") +\n",
    "  expand_limits(x = c(0,1))\n",
    "} \n",
    "\n",
    "plot_winpercentage(teamperf, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Straight away we can see that there are some potential issues with our dataset.\n",
    "\n",
    "For one thing, some countries have ceased to exist, either because they dissolved into multiple countries - for example the Soviet Union (`URS`), Yugoslavia (`YUG`) or Czechoslovakia (`TCH`), or because they united into one country - like it was the case with the [German reunification](https://en.wikipedia.org/wiki/German_reunification) of 1990. In the latter case, West Germany (`FRG`) and East Germany (`GDR`) unified into a single Germany (`GER`). \n",
    "\n",
    "Another case was when a country would rename itself - for example from Zaire (`ZAI`) to Democratic Republic of the Congo (`COD`).\n",
    "\n",
    "Here is a complete list of all the FIFA [obsolete country codes](https://en.wikipedia.org/wiki/List_of_FIFA_country_codes#Obsolete_country_codes) which stood for countries and territories that no longer exist.\n",
    "\n",
    "From our perspective, for the purposes of continuity we would like to consider the new countries as successors to (part of) the old ones, because it will allow us to take past performance into account instead of starting from scratch. The process is not 100% straightforward - for example, which of the [six countries](https://en.wikipedia.org/wiki/Breakup_of_Yugoslavia) should we consider as a succesor to Yugoslavia? - but we will undergo a best effort approach. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T13:41:11.122575Z",
     "start_time": "2018-06-18T13:41:09.331Z"
    }
   },
   "outputs": [],
   "source": [
    "# transform old country codes into new ones.\n",
    "countryCodeMappings <- matrix(c(\n",
    "  \"FRG\",\"GER\",\n",
    "  \"TCH\",\"CZE\",\n",
    "  \"URS\",\"RUS\",\n",
    "  \"SCG\",\"SRB\",\n",
    "  \"ZAI\",\"COD\"\n",
    "  ), ncol=2, byrow = TRUE)\n",
    "\n",
    "for (i in 1:nrow(countryCodeMappings)) {\n",
    "  teamperf$name[teamperf$name == countryCodeMappings[i,1]] <- countryCodeMappings[i,2]\n",
    "  teamperf$opponentName[teamperf$opponentName == countryCodeMappings[i,1]] <- countryCodeMappings[i,2]\n",
    "  \n",
    "  matches$team1[matches$team1 == countryCodeMappings[i,1]] <- countryCodeMappings[i,2]\n",
    "  matches$team2[matches$team2 == countryCodeMappings[i,1]] <- countryCodeMappings[i,2]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T13:41:11.124482Z",
     "start_time": "2018-06-18T13:41:09.336Z"
    }
   },
   "outputs": [],
   "source": [
    "# let's run the win percentage graph again\n",
    "plot_winpercentage(teamperf, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our model will predict match results, it would be useful to also look at the distribution of match scores as well as total number of goals scored per game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T13:41:11.126376Z",
     "start_time": "2018-06-18T13:41:09.683Z"
    }
   },
   "outputs": [],
   "source": [
    "# what is the occurence frequency for match scores?\n",
    "\n",
    "scorefreq <- matches %>%\n",
    "  group_by(team1Score, team2Score) %>%\n",
    "  summarise(\n",
    "    n = n(),\n",
    "    freq = n / nrow(matches)\n",
    "  ) %>%\n",
    "  ungroup() %>%\n",
    "  mutate(\n",
    "    scoretext = paste(team1Score,\"-\",team2Score)\n",
    "  ) %>%\n",
    "  arrange(desc(freq)) \n",
    "\n",
    "  head(scorefreq, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T13:41:11.128303Z",
     "start_time": "2018-06-18T13:41:09.689Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# distribution of goals scored per match\n",
    "gsfreq <- matches %>%\n",
    "  group_by(gs = team1Score + team2Score) %>%\n",
    "  summarise(\n",
    "    n = n(),\n",
    "    freq = n / nrow(matches)\n",
    "  ) %>%\n",
    "  ungroup() %>%\n",
    "  arrange(desc(freq)) \n",
    "\n",
    "head(gsfreq, 10)\n",
    "\n",
    "gsfreq %>%\n",
    "  filter(freq >= 0.01) %>%\n",
    "  ggplot(mapping = aes(x = gs, y = freq)) + geom_bar(stat = \"identity\") + ggtitle(\"Goals scored per match distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T13:41:11.130201Z",
     "start_time": "2018-06-18T13:41:09.696Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# distribution of goal differential\n",
    "gdfreq <- matches %>%\n",
    "  group_by(gd = team1Score - team2Score) %>%\n",
    "  summarise(\n",
    "    n = n(),\n",
    "    freq = n / nrow(matches)\n",
    "  ) %>%\n",
    "  ungroup() %>%\n",
    "  arrange(gd) \n",
    "\n",
    "head(gdfreq %>% filter(abs(gd)<=4), 10)\n",
    "\n",
    "gdfreq %>%\n",
    "  filter(abs(gd)<=4) %>%\n",
    "  ggplot(mapping = aes(x = gd, y = freq)) + geom_bar(stat = \"identity\") + ggtitle(\"Goal differential distribution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outliers ###\n",
    "\n",
    "Since our aim is to predict the goal differential (win margin) between the two teams in a match, we'd like to get rid of *outliers* - values which are far away at the end of the spectrum of possible values for this variable. The reason is that outliers can drastically change the results of the data analysis and statistical modeling. Outliers increase the error variance, reduce the power of statistical tests, and ultimately they can bias or influence estimates.\n",
    "\n",
    "So let's deal with all matches where **the goal differential is greater than 7**. \n",
    "\n",
    "First, let's verify how many of those we've got in the first place:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T13:41:11.132434Z",
     "start_time": "2018-06-18T13:41:10.008Z"
    }
   },
   "outputs": [],
   "source": [
    "# how many outliers do we have?\n",
    "temp <- matches %>% dplyr::filter(abs(team1Score - team2Score) > 7)\n",
    "head(temp)\n",
    "paste(nrow(temp), \"matches, or\", (nrow(temp)/nrow(matches)*100), \"% of total.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad - only a very small percentage of games would be outliers as per our definition. \n",
    "\n",
    "> NOTE: As a rule of thumb, any value which is out of range of the 5th and 95th percentile may be considered an outlier.\n",
    " \n",
    "Let's deal with the outliers in `teamperf` by capping the goal differential to the [-7, +7] interval:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T13:41:11.134326Z",
     "start_time": "2018-06-18T13:41:10.320Z"
    }
   },
   "outputs": [],
   "source": [
    "# get rid of all the outliers by capping the gd to [-7, +7]\n",
    "teamperf$gd[teamperf$gd < -7] <- -7\n",
    "teamperf$gd[teamperf$gd > +7] <- +7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strength of opposition ###\n",
    "\n",
    "We may also want to take into account the fact that teams play most of their matches against opponents from the same [FIFA Confederation](http://www.fifa.com/associations/index.html) - for example, European teams play mostly against other UEFA members, while African teams face other CAF members for the most part. Only during final tournaments like the Olympics, the World Cup and the Confederations Cup will teams play official (non-friendly) matches against non-confederation opponents. \n",
    "\n",
    "Since not all conferences are the same general strength, we can adjust our `teamperf` dataset to also include information about the conference the opponent belongs to. We can assign adjustment coefficients to each conference, in a similar way to how FIFA's World ranking algorithm [accounts for regional strength](https://en.wikipedia.org/wiki/FIFA_World_Rankings#Regional_strength)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T13:41:11.136222Z",
     "start_time": "2018-06-18T13:41:10.651Z"
    }
   },
   "outputs": [],
   "source": [
    "# get information about the various FIFA confederations and the teams they contain\n",
    "if(!file.exists(\"teams.csv\")){\n",
    "  tryCatch(download.file('https://raw.githubusercontent.com/neaorin/PredictTheWorldCup/master/input/teams.csv'\n",
    "                         ,destfile=\"./teams.csv\",method=\"auto\"))\n",
    "}\n",
    "\n",
    "if(file.exists(\"teams.csv\")) teams <- read_csv(\"teams.csv\")\n",
    "\n",
    "# confederations and adjustment coefficients for them\n",
    "confederations <- as.data.frame(matrix(c(\n",
    "  \"UEFA\",\"0.99\",\n",
    "  \"CONMEBOL\",\"1.00\",\n",
    "  \"CONCACAF\",\"0.85\",\n",
    "  \"AFC\",\"0.85\",\n",
    "  \"CAF\",\"0.85\",\n",
    "  \"OFC\",\"0.85\"\n",
    "), ncol=2, byrow = TRUE, dimnames = list(NULL, c(\"confederation\",\"adjust\"))), stringsAsFactors = FALSE)\n",
    "\n",
    "confederations$confederation <- as.vector(confederations$confederation)\n",
    "confederations$adjust <- as.numeric(confederations$adjust)\n",
    "\n",
    "# add a confederation coefficient for the opponent faced \n",
    "teamperf <- teamperf %>%\n",
    "  dplyr::left_join(teams, by=c(\"opponentName\" = \"fifa_code\")) %>%\n",
    "  dplyr::left_join(confederations, by=c(\"confederation\")) %>%\n",
    "  dplyr::mutate(\n",
    "    opponentConfederationCoefficient = adjust\n",
    "  ) %>%\n",
    "dplyr::select(match_id, date, name = name.x, opponentName, opponentConfederationCoefficient,  homeVenue, neutralVenue, gs, ga, gd, w, l, d, friendly, qualifier, finaltourn)\n",
    "\n",
    "# set missing values to 1\n",
    "teamperf$opponentConfederationCoefficient[is.na(teamperf$opponentConfederationCoefficient)] <- 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Feature Engineering ##\n",
    "\n",
    "Now, let's calculate some lag features for each team which is about to play a game.\n",
    "\n",
    "We'll look at the previous `N` games a team has played, up to the game in question, and we'll calculate the percentage of wins, draws, losses, as well as the goal differential, per game, for those past `N` games.\n",
    "\n",
    "For example, taking `N=10`:\n",
    "\n",
    "```\n",
    "last10games_w_per = (number of wins in the past 10 games) / 10\n",
    "last10games_d_per = (number of draws in the past 10 games) / 10\n",
    "last10games_l_per = (number of losses in the past 10 games) / 10\n",
    "last10games_gd_per = (goals scored - goals conceeded in the past 10 games) / 10 \n",
    "```\n",
    "\n",
    "We'll use three different values for `N` (10, 30 and 50) to capture short-, medium-, and long-term form.\n",
    "\n",
    "We'll calculate those values for every team and every game in our dataset.\n",
    "\n",
    "To model the strength of opposition faced, we'll use the same technique with respect to the `opponentConfederationCoefficient` values we introduced earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T13:41:11.138115Z",
     "start_time": "2018-06-18T13:41:10.991Z"
    }
   },
   "outputs": [],
   "source": [
    "# Let's calculate some lag features for each team which is about to play a game\n",
    "# we'll take three windows: last 5 games, last 20 games, last 35 games.\n",
    "# for each window we'll calculate some values\n",
    "\n",
    "lagfn <- function(data, width) {\n",
    "  return (rollapplyr(data, width = width + 1, FUN = sum, fill = NA, partial=TRUE) - data)\n",
    "}\n",
    "\n",
    "lagfn_per <- function(data, width) {\n",
    "  return (lagfn(data, width) / width)\n",
    "}\n",
    "\n",
    "team_features <- teamperf %>%\n",
    "  dplyr::arrange(name, date) %>%\n",
    "  dplyr::group_by(name) %>%\n",
    "  dplyr::mutate(\n",
    "    last10games_w_per = lagfn_per(w, 10),\n",
    "    last30games_w_per = lagfn_per(w, 30),\n",
    "    last50games_w_per = lagfn_per(w, 50),\n",
    "\n",
    "    last10games_l_per = lagfn_per(l, 10),\n",
    "    last30games_l_per = lagfn_per(l, 30),\n",
    "    last50games_l_per = lagfn_per(l, 50),\n",
    "\n",
    "    last10games_d_per = lagfn_per(d, 10),\n",
    "    last30games_d_per = lagfn_per(d, 30),\n",
    "    last50games_d_per = lagfn_per(d, 50),\n",
    "            \n",
    "    last10games_gd_per = lagfn_per(gd, 10),\n",
    "    last30games_gd_per = lagfn_per(gd, 30),\n",
    "    last50games_gd_per = lagfn_per(gd, 50),\n",
    "      \n",
    "    last10games_opp_cc_per = lagfn_per(opponentConfederationCoefficient, 10),\n",
    "    last30games_opp_cc_per = lagfn_per(opponentConfederationCoefficient, 30),\n",
    "    last50games_opp_cc_per = lagfn_per(opponentConfederationCoefficient, 50)\n",
    "\n",
    "  ) %>%\n",
    "  dplyr::select (\n",
    "    match_id, date, name, opponentName, gs, ga,\n",
    "    w, last10games_w_per, last30games_w_per, last50games_w_per,\n",
    "    l, last10games_l_per, last30games_l_per, last50games_l_per,\n",
    "    d, last10games_d_per, last30games_d_per, last50games_d_per,\n",
    "    gd, last10games_gd_per, last30games_gd_per, last50games_gd_per,\n",
    "    opponentConfederationCoefficient, last10games_opp_cc_per, last30games_opp_cc_per, last50games_opp_cc_per\n",
    "\n",
    "          ) %>%\n",
    "  dplyr::ungroup()\n",
    "\n",
    "head((team_features %>% dplyr::filter(name == \"BRA\" & date >= '1970-01-01')), n = 20)\n",
    "summary(team_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have built a series of team-specific features, we need to fold them back into match-specific features.\n",
    "\n",
    "We will then have a set of features for both teams about to face each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T13:41:11.385615Z",
     "start_time": "2018-06-18T13:41:11.342Z"
    }
   },
   "outputs": [],
   "source": [
    "# fold per-team features into per-match features\n",
    "match_features <- matches %>%\n",
    "  left_join(team_features, by=c(\"match_id\", \"team1\" = \"name\")) %>%\n",
    "  left_join(team_features, by=c(\"match_id\", \"team2\" = \"name\"), suffix=c(\".t1\",\".t2\")) %>%\n",
    "  dplyr::select(\n",
    "    date, match_id, team1, team2, team1Home, team2Home, neutralVenue, team1Score, team2Score, friendly, qualifier, finaltourn,\n",
    "    last10games_w_per.t1,\n",
    "    last30games_w_per.t1,\n",
    "    last50games_w_per.t1,\n",
    "    last10games_l_per.t1,\n",
    "    last30games_l_per.t1,\n",
    "    last50games_l_per.t1,\n",
    "    last10games_d_per.t1,\n",
    "    last30games_d_per.t1,\n",
    "    last50games_d_per.t1,\n",
    "    last10games_gd_per.t1, \n",
    "    last30games_gd_per.t1,\n",
    "    last50games_gd_per.t1,\n",
    "    last10games_opp_cc_per.t1, \n",
    "    last30games_opp_cc_per.t1, \n",
    "    last50games_opp_cc_per.t1,\n",
    "    last10games_w_per.t2,\n",
    "    last30games_w_per.t2,\n",
    "    last50games_w_per.t2,\n",
    "    last10games_l_per.t2,\n",
    "    last30games_l_per.t2,\n",
    "    last50games_l_per.t2,\n",
    "    last10games_d_per.t2,\n",
    "    last30games_d_per.t2,\n",
    "    last50games_d_per.t2,\n",
    "    last10games_gd_per.t2, \n",
    "    last30games_gd_per.t2,\n",
    "    last50games_gd_per.t2,\n",
    "    last10games_opp_cc_per.t2, \n",
    "    last30games_opp_cc_per.t2, \n",
    "    last50games_opp_cc_per.t2,\n",
    "    outcome = gd.t1\n",
    "  )\n",
    "\n",
    "head(match_features)\n",
    "names(match_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're also going to get rid of some columns which should not be used in training - specifically `team1Score` and `team2Score`. We will use the new `outcome` column instead - which is the difference between `team1Score` and `team2Score`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T13:41:11.769329Z",
     "start_time": "2018-06-18T13:41:11.734Z"
    }
   },
   "outputs": [],
   "source": [
    "# drop all non-interesting columns, and those which should not be supplied for new data (like scores)\n",
    "match_features <- match_features %>%\n",
    "  dplyr::select(-c(match_id,team1Score,team2Score))\n",
    "\n",
    "head(match_features)\n",
    "names(match_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also have a look at how correlated our numeric features are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T13:41:12.172092Z",
     "start_time": "2018-06-18T13:41:12.136Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# correlation matrix\n",
    "cormatrix <- cor(match_features %>% dplyr::select(-c(date, team1, team2, team1Home, team2Home, neutralVenue, friendly, qualifier, finaltourn)) )\n",
    "corrplot(cormatrix, type = \"upper\", order = \"original\", tl.col = \"black\", tl.srt = 45, tl.cex = 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, we don't have a lot of surprises here. It looks like goal differential lag values are strongly correlated with win and loss lag values (as expected).\n",
    "\n",
    "Also, we have strong positive correlations between lag features measuring the same metric on different lag windows. For example, `last10games_w_per.t1`, `last30games_w_per.t1` and `last50games_w_per.t1` are correlated. Also unsurprisingly, the correlation between 10- and 50- window metrics are weaker than between 10- and 30-, or 30- and 50-. But it does seem to suggest that good teams generally keep being good over time, and bad teams keep being bad. \n",
    "\n",
    "Last, none of our features has a correlation value (positive or negative) with our `outcome` that's much stronger than others. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training our first model ##\n",
    "\n",
    "The next step is to create a training formula for our model - it is going to describe the features we want to use and the outcome we're trying to predict. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T13:41:12.940573Z",
     "start_time": "2018-06-18T13:41:12.904Z"
    }
   },
   "outputs": [],
   "source": [
    "# create the training formula \n",
    "trainformula <- as.formula(paste('outcome',\n",
    "                                 paste(names(match_features %>% dplyr::select(-c(date,team1,team2,outcome))),collapse=' + '),\n",
    "                                 sep=' ~ '))\n",
    "trainformula"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to split our `match_features` into a training and a testing dataset. We're going to be using the training data to fit our model, then we're going to use the testing data to evaluate its accuracy.\n",
    "\n",
    "We're going to use the matches from 1960 - 2009 to train our model, and the matches from 2010 - present to validate it.\n",
    "\n",
    "> NOTE: Although we're going to skip this step for the tutorial, [model cross validation](https://en.wikipedia.org/wiki/Cross-validation_(statistics)) is an important step to verify how a model will respond to a new, unknown data set. We would be creating multiple \"folds\" of training and testing set combinations from our original data set, and validate each combination to obtain a more complete picture of our model's predictive power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T13:41:13.328377Z",
     "start_time": "2018-06-18T13:41:13.290Z"
    }
   },
   "outputs": [],
   "source": [
    "# training and testing datasets\n",
    "\n",
    "data.train1 <- match_features %>% dplyr::filter(date < '2009/1/1')\n",
    "data.test1 <- match_features %>% dplyr::filter(date >= '2009/1/1' & date <= '2015/1/1')\n",
    "\n",
    "nrow(data.train1)\n",
    "nrow(data.test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to train our model. \n",
    "\n",
    "Since we're going to train a model to predict a numeric value (goal differential), we have a [wide choice of regression algorithms](https://docs.microsoft.com/en-us/azure/machine-learning/machine-learning-algorithm-cheat-sheet) we could use:\n",
    "\n",
    "- linear regression\n",
    "- neural network regression\n",
    "- decision forest regression\n",
    "- boosted decision tree regression\n",
    "- etc.\n",
    "\n",
    "Indeed we might decide to try several algorithms, with a variety of parameter combinations for each of them, in order to find the optimal model and training strategy. \n",
    "\n",
    "For this tutorial we're going to use a [random forest](https://cran.r-project.org/web/packages/randomForest/index.html), an algorithm which grows multiple [decision trees](https://en.wikipedia.org/wiki/Decision_tree_learning) from the features presented to it, and has each individual tree \"vote\" on the outcome for each new input vector (or in other words, new match to predict). It's fast, fairly accurate, and it gives an unbiased estimate of the generalization error, which makes cross-validation unnecessary for this particular algorithm.\n",
    "\n",
    "The R implementation of the random forest algorithm is available in the [randomForest](https://cran.r-project.org/web/packages/randomForest/index.html) package.\n",
    "\n",
    "We're going to tell the algorithm to grow 500 trees. \n",
    "\n",
    "> NOTE: The training process should take several minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T13:41:13.714777Z",
     "start_time": "2018-06-18T13:41:13.679Z"
    }
   },
   "outputs": [],
   "source": [
    "# train a random forest\n",
    "model.randomForest1 <- randomForest::randomForest(trainformula, data = data.train1, \n",
    "                                                  importance = TRUE, ntree = 500)\n",
    "\n",
    "summary(model.randomForest1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation ##\n",
    "\n",
    "In order to understand the importance of our predictors to the predicted `outcome`, we can use some built-in functions from the `randomForest` package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T13:41:14.105877Z",
     "start_time": "2018-06-18T13:41:14.071Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "randomForest::importance(model.randomForest1, type=1)\n",
    "randomForest::varImpPlot(model.randomForest1, type=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now expose our trained model to the test dataset, and calculate indicators related to its accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T13:41:14.512889Z",
     "start_time": "2018-06-18T13:41:14.475Z"
    }
   },
   "outputs": [],
   "source": [
    "data.pred.randomForest1 <- predict(model.randomForest1, data.test1, predict.all = TRUE)\n",
    "\n",
    "metrics.randomForest1.mae <- Metrics::mae(data.test1$outcome, data.pred.randomForest1$aggregate)\n",
    "metrics.randomForest1.rmse <- Metrics::rmse(data.test1$outcome, data.pred.randomForest1$aggregate)\n",
    "\n",
    "paste(\"Mean Absolute Error:\", metrics.randomForest1.mae)\n",
    "paste(\"Root Mean Square Error:\",metrics.randomForest1.rmse)\n",
    "\n",
    "abs_error <- abs(data.test1$outcome - data.pred.randomForest1$aggregate)\n",
    "plot(abs_error, main=\"Mean Absolute Error\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T13:41:14.519856Z",
     "start_time": "2018-06-18T13:41:14.481Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#check the largest MAE error\n",
    "crazy_error <- which(abs_error > 8)\n",
    "data.test1[crazy_error,]\n",
    "data.pred.randomForest1$aggregate[crazy_error]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Simulating the Tournament ##\n",
    "\n",
    "With a trained model at our disposal, we can now run tournament simulations on it. \n",
    "\n",
    "For example, let's take the [qualified teams](https://en.wikipedia.org/wiki/2018_FIFA_World_Cup#Qualified_teams) for the FIFA 2018 World Cup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T13:41:14.950620Z",
     "start_time": "2018-06-18T13:41:14.915Z"
    }
   },
   "outputs": [],
   "source": [
    "if(!file.exists(\"wc2018qualified.csv\")){\n",
    "    tryCatch(download.file('https://raw.githubusercontent.com/neaorin/PredictTheWorldCup/master/src/TournamentSim/wc2018qualified.csv'\n",
    "                           ,destfile=\"./wc2018qualified.csv\",method=\"auto\"))\n",
    "}\n",
    "                \n",
    "if(file.exists(\"wc2018qualified.csv\")) qualified <- read_csv(\"wc2018qualified.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now run the entire tournament 10,000 times, calling into the model to get a prediction for each match.\n",
    "\n",
    "For performance reasons, we could generate **all the the possible two-team combinations**, then ask the model for predictions for each combination, and then store those predictions. \n",
    "\n",
    "We can store the mean values, as well as the standard deviation of the predicted values from every one of our decision trees. This will allow us to simulate a more realistic distribution of results, for multiple iterations of the same match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T13:41:15.425450Z",
     "start_time": "2018-06-18T13:41:15.370Z"
    }
   },
   "outputs": [],
   "source": [
    "# get a list of possible matches to be played at the world cup\n",
    "\n",
    "data.topredict <- expand.grid(team1 = qualified$name, team2 = qualified$name, stringsAsFactors = FALSE) %>% filter(team1 < team2)\n",
    "\n",
    "temp <- teamperf %>%\n",
    "  semi_join(qualified, by = c(\"name\")) %>%\n",
    "  group_by(name) %>%\n",
    "  summarise(\n",
    "    date = max(date)\n",
    "  )\n",
    "\n",
    "temp <- team_features %>%\n",
    "  semi_join(temp, by = c(\"name\", \"date\"))\n",
    "\n",
    "# calculate the features for every possbile match\n",
    "\n",
    "data.topredict <- data.topredict %>%\n",
    "  left_join(temp, by = c(\"team1\" = \"name\")) %>%\n",
    "  left_join(temp, by = c(\"team2\" = \"name\"), suffix = c(\".t1\", \".t2\")) %>%\n",
    "  dplyr::select(\n",
    "    team1, team2,\n",
    "    last10games_w_per.t1,\n",
    "    last30games_w_per.t1,\n",
    "    last50games_w_per.t1,\n",
    "    last10games_l_per.t1,\n",
    "    last30games_l_per.t1,\n",
    "    last50games_l_per.t1,\n",
    "    last10games_d_per.t1,\n",
    "    last30games_d_per.t1,\n",
    "    last50games_d_per.t1,\n",
    "    last10games_gd_per.t1, \n",
    "    last30games_gd_per.t1,\n",
    "    last50games_gd_per.t1,\n",
    "    last10games_opp_cc_per.t1, \n",
    "    last30games_opp_cc_per.t1, \n",
    "    last50games_opp_cc_per.t1,\n",
    "    last10games_w_per.t2,\n",
    "    last30games_w_per.t2,\n",
    "    last50games_w_per.t2,\n",
    "    last10games_l_per.t2,\n",
    "    last30games_l_per.t2,\n",
    "    last50games_l_per.t2,\n",
    "    last10games_d_per.t2,\n",
    "    last30games_d_per.t2,\n",
    "    last50games_d_per.t2,\n",
    "    last10games_gd_per.t2, \n",
    "    last30games_gd_per.t2,\n",
    "    last50games_gd_per.t2,\n",
    "    last10games_opp_cc_per.t2, \n",
    "    last30games_opp_cc_per.t2, \n",
    "    last50games_opp_cc_per.t2      \n",
    "  ) %>%\n",
    "  mutate(\n",
    "    date = as.POSIXct(\"2018-06-14\"), \n",
    "    team1Home = (team1 == \"RUS\"), team2Home = (team2 == \"RUS\"), neutralVenue = !(team1Home | team2Home), \n",
    "    friendly = FALSE, qualifier = FALSE, finaltourn = TRUE\n",
    "  )\n",
    "\n",
    "head(data.topredict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, our `data.topredict` table contains all the possible two-team match combinations, with calculated features for each team. \n",
    "\n",
    "We can now ask our model to predict outcomes for these matches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T13:41:15.859762Z",
     "start_time": "2018-06-18T13:41:15.823Z"
    }
   },
   "outputs": [],
   "source": [
    "# ask the model to predict our world cup matches\n",
    "data.predicted <- predict(model.randomForest1, data.topredict, predict.all = TRUE)\n",
    "\n",
    "head(data.predicted$individual)\n",
    "head(data.predicted$aggregate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, for every game in our input dataset, we've got the individual predictions from every one of our 100 decision trees, as well as the mean value of those predictions.\n",
    "\n",
    "We're going to save the mean values, as well as the [standard deviation](https://en.wikipedia.org/wiki/Standard_deviation) of the 100 individual predictions. The standard deviation is a measure of how \"dispersed\" our values are; in other words, how close (or far away from) the mean the individual values are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the standard deviation of the individual predictions of each match\n",
    "\n",
    "data.predicted$sd = apply(data.predicted$individual, c(1), sd)\n",
    "\n",
    "# keep only the interesting columns for running tournament simulations\n",
    "data.staticpred <- data.topredict %>% \n",
    "  dplyr::select(team1, team2)\n",
    "\n",
    "data.staticpred$outcome = data.predicted$aggregate\n",
    "data.staticpred$sd = data.predicted$sd\n",
    "\n",
    "head(data.staticpred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the mean and standard deviation values to pick an individual outcome for a match. For example, we can use the [normal distribution](https://en.wikipedia.org/wiki/Normal_distribution) in conjunction with R's [`rnorm`](https://stat.ethz.ch/R-manual/R-devel/library/stats/html/Normal.html) function to pick an outcome for a match where we have obtained a predicted mean and standard deviation from the model.\n",
    "\n",
    "For instance, let's assume we need to provide predicted outcomes for a Brazil vs Argentina match. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp <- data.staticpred %>% dplyr::filter(team1 == \"ARG\" & team2 == \"BRA\")\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(4342)\n",
    "draw_threshold <- 0.4475\n",
    "\n",
    "temp2 <- rnorm(100, temp$outcome, temp$sd)\n",
    "temp2\n",
    "\n",
    "plot(round(temp2),xlab=\"Match Index\",ylab=\"Goal Diff\", main=\"ARG vs BRA, 100 simulated matches\")\n",
    "abline(h = 0, v = 0, col = \"gray60\")\n",
    "abline(h = -0.4475, v = 0, col = \"gray60\", lty=3)\n",
    "abline(h = +0.4475, v = 0, col = \"gray60\", lty=3)\n",
    "mtext(c(\"BRA\",\"Draw\",\"ARG\"),side=2,line=-3,at=c(-3,0,3),col= \"red\")\n",
    "\n",
    "paste(\"ARG won\", length(temp2[temp2 > +draw_threshold]), \"matches.\")\n",
    "paste(\"BRA won\", length(temp2[temp2 < -draw_threshold]), \"matches.\")\n",
    "paste(length(temp2[temp2 >= -draw_threshold & temp2 <= +draw_threshold]), \"matches drawn.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The points in the above graph are individual outcomes (goal differentials) which we can round to the nearest integer, or to a predicted draw - in the case of values that are \"close enough\" to zero.\n",
    "\n",
    "Let's have a look at the result distribution for the real-world matches between these two teams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# real results of ARG vs BRA matches\n",
    "temp <- as.vector(teamperf %>% filter(name == \"ARG\" & opponentName == \"BRA\") %>% dplyr::select(gd))\n",
    "\n",
    "plot(temp$gd,xlab=\"Match Index\",ylab=\"Goal Diff\", main=\"ARG vs BRA, real matches\")\n",
    "abline(h = 0, v = 0, col = \"gray60\")\n",
    "abline(h = -0.4475, v = 0, col = \"gray60\", lty=3)\n",
    "abline(h = +0.4475, v = 0, col = \"gray60\", lty=3)\n",
    "mtext(c(\"BRA\",\"Draw\",\"ARG\"),side=2,line=-3,at=c(-3,0,3),col= \"red\")\n",
    "\n",
    "paste(\"ARG won\", nrow(temp %>% dplyr::filter(gd > 0)), \"matches.\")\n",
    "paste(\"BRA won\", nrow(temp %>% dplyr::filter(gd < 0)), \"matches.\")\n",
    "paste(nrow(temp %>% dplyr::filter(gd == 0)), \"matches drawn.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For comparison, let's also generate a plot for outcomes of a more unbalanced match-up: Argentina vs Egypt. Incidentally, these two teams have NEVER met in an official match before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(4342)\n",
    "\n",
    "temp <- data.staticpred %>% dplyr::filter(team1 == \"ARG\" & team2 == \"EGY\")\n",
    "temp\n",
    "\n",
    "temp2 <- rnorm(100, temp$outcome, temp$sd)\n",
    "\n",
    "plot(round(temp2),xlab=\"Match Index\",ylab=\"Goal Diff\", main=\"ARG vs EGY, 100 simulated matches\")\n",
    "abline(h = 0, v = 0, col = \"gray60\")\n",
    "abline(h = -0.4475, v = 0, col = \"gray60\", lty=3)\n",
    "abline(h = +0.4475, v = 0, col = \"gray60\", lty=3)\n",
    "mtext(c(\"EGY\",\"Draw\",\"ARG\"),side=2,line=-3,at=c(-3,0,3), col=\"red\")\n",
    "\n",
    "paste(\"ARG won\", length(temp2[temp2 > +draw_threshold]), \"matches.\")\n",
    "paste(\"EGY won\", length(temp2[temp2 < -draw_threshold]), \"matches.\")\n",
    "paste(length(temp2[temp2 >= -draw_threshold & temp2 <= +draw_threshold]), \"matches drawn.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, starting from a rather inconspicuous-looking prediction we can generate a number of possible match results which, while respecting a World Cup's surprising nature, is still in line with what experience tells us *should* happen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tournament Statistics\n",
    "\n",
    "Now that we're armed with a way of generating multiple predictions for every possible game in the World Cup, we can write a [rather straightforward program](https://github.com/neaorin/PredictTheWorldCup/blob/master/src/TournamentSim/simulateworldcup.py) to run the tournament a large number of times - for example 10,000 iterations. \n",
    "\n",
    "We can save our predictions to a CSV file and use it as input for the simulator program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_csv(data.staticpred, \"wc2018staticPredictions.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can run the program. You simply need [Python 3.x](https://www.python.org/downloads/) installed in order to run it.\n",
    "\n",
    "Clone the [GitHub repository](https://github.com/neaorin/PredictTheWorldCup), then `cd` to the correct folder, and run it.\n",
    "\n",
    "Assuming a Windows machine, the steps you need to perform should look like the following, with Python 3 already installed:\n",
    "\n",
    "```bat\n",
    "git clone https://github.com/neaorin/PredictTheWorldCup.git\n",
    "cd PredictTheWorldCup\\src\\TournamentSim\n",
    "python simulateworldcup.py\n",
    "```\n",
    "\n",
    "On a Linux or Mac the steps should be similar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The program will output a list of tournament winners (one for each iteration) to a `simresults.csv` file. \n",
    "\n",
    "The R code that's going to run after this step will attempt to download a version of this file from the GitHub repository; however, if you ran the Python program yourself and would like to use your own `simresults.csv` file, you can simply upload it into this Azure Notebook library by using the `Data / Upload...` menu at the top of this notebook.\n",
    "\n",
    "Once we have the results inside the `simresults.csv` file, we can load it up into R and see who won tournaments, and who didn't:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the results of the simulation program\n",
    "\n",
    "if(!file.exists(\"simresults.csv\")){\n",
    "    tryCatch(download.file('https://raw.githubusercontent.com/neaorin/PredictTheWorldCup/master/src/TournamentSim/simresults.csv'\n",
    "                           ,destfile=\"./simresults.csv\",method=\"auto\"))\n",
    "}\n",
    "                \n",
    "if(file.exists(\"simresults.csv\")) simresults <- read_csv(\"simresults.csv\")\n",
    "    \n",
    "head(simresults, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot the winners\n",
    "\n",
    "winsperteam <- simresults %>%\n",
    "  dplyr::group_by(winner) %>%\n",
    "  dplyr::summarize(\n",
    "    wins = n()\n",
    "  ) %>%\n",
    "  dplyr::arrange(desc(wins)) \n",
    "\n",
    "winsperteam$winner <- factor(winsperteam$winner, levels = winsperteam$winner[order(winsperteam$wins, decreasing = FALSE)])\n",
    "\n",
    "ggplot(winsperteam, mapping = aes(x=winner, y=wins)) +\n",
    "  geom_bar(stat=\"identity\") +\n",
    "  coord_flip() +\n",
    "  geom_text(aes(label=paste(wins / 100, \"%\")), vjust=0.3, hjust=-0.1, size=2.1) +\n",
    "  ggtitle(\"Tournament simulation winners (10,000 iterations)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just for fun, let's calculate the odds to win the tournament predicted by our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# calculate the sports odds \n",
    "\n",
    "winsperteam$odds <- lengths(simresults) / winsperteam$wins\n",
    "writeLines(paste(winsperteam$winner, \": \",round(winsperteam$odds), \" to 1\\n\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's it! We now have a surefire way of making money by betting on sports! \n",
    "\n",
    "*(pretty sure I'm not the first person ever to say those words :P)*\n",
    "\n",
    "Sorin"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
